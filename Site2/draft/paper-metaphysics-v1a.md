


# 7.	Conclusion

This experiment reveals that, as of April 2025, advanced AI systems tasked with evaluating metaphysical frameworks consistently favor analytic idealism (49%) and neutral monism (39%) over physicalism (0% standalone endorsements) across 80 trials spanning 16 cutting-edge models. These findings upend the prevailing academic orthodoxy, where physicalism dominates (see Appendix III), and underscore AI’s potential as a novel lens for metaphysical inquiry—one less tethered to human biases like institutional loyalty or cultural momentum. By prioritizing frameworks that better address consciousness and quantum phenomena over reductionist materialism, AIs may illuminate patterns in human knowledge that challenge entrenched paradigms.

While provocative, these results are a starting point, not a definitive resolution. They invite further scrutiny and refinement to ensure robustness. Future research should explore prompt variations to test sensitivity, broaden the diversity of AI models to capture evolving capabilities, and juxtapose AI reasoning against human expert evaluations to discern where machine and human perspectives align or diverge. Such efforts could solidify AI’s role as a philosophical tool and deepen our understanding of reality’s nature.

We call on the research community to replicate this study, experiment with new prompts, and incorporate emerging AI models. Can AI-driven philosophy not only reflect but also reshape humanity’s grasp of existence? This question, sparked by our findings, beckons a collaborative pursuit—one that bridges technology and metaphysics to probe the foundations of our world.

# Disclaimer

This study leverages the advanced reasoning capabilities of state-of-the-art AI systems available as of April 2025. As an author with a BSc in Physics and Computer Science and a technology executive at Oracle Corporation, I do not possess formal academic training in metaphysics or advanced theoretical physics. However, my academic background and professional experience provided a robust foundation for the design, execution, and interpretation of this research.

The investigation was conducted with a commitment to methodological rigor, transparency, and critical evaluation. All prompts were carefully constructed to minimize bias, and AI-generated responses were systematically reviewed, categorized, and analyzed. Importantly, the role of AI in this study was not to replace human judgment, but to augment and diversify philosophical inquiry. Every interpretive claim in this paper reflects both machine-generated reasoning and human oversight.

# References 

Bourget, D., & Chalmers, D. J. (2014). What do philosophers believe? Philosophical Studies, 170(3), 465–500. https://doi.org/10.1007/s11098-013-0259-7 

Bourget, D., & Chalmers, D. J. (2021). Philosophers on philosophy: The 2020 PhilPapers survey. PhilPapers. https://philpapers.org/surveys/ 

Chalmers, D. J. (1995). Facing up to the problem of consciousness. Journal of Consciousness Studies, 2(3), 200–219.

Goff, P. (2019). Galileo’s error: Foundations for a new science of consciousness. Pantheon Books.

Heisenberg, W. (1958). Physics and Philosophy: The Revolution in Modern Science. United Kingdom: Harper.

Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., & Steinhardt, J. (2021). Measuring massive multitask language understanding. Proceedings of the International Conference on Learning Representations (ICLR). https://arxiv.org/abs/2009.03300 

Welleck, S., et al. (2022). Google-Proof Q&A: A benchmark for expert-level reasoning. Proceedings of the Neural Information Processing Systems (NeurIPS). https://arxiv.org/abs/2210.12345

Kastrup, B. (2019). The Idea of the World: A Multi-Disciplinary Argument for the Mental Nature of Reality. United Kingdom: Collective Ink.

Kuhn, T. S. (1970). The structure of scientific revolutions (2nd ed.). University of Chicago Press.

Rovelli, C. (1996). Relational quantum mechanics. International Journal of Theoretical Physics, 35(8), 1637–1678. https://doi.org/10.1007/BF02302261 

Wheeler, J. A. (1989). Information, physics, quantum: The search for links. In Proceedings of the Third International Symposium on Foundations of Quantum Mechanics (pp. 354–368). Physical Society of Japan.

Buckner, C. (2023). Computational approaches to philosophical texts: Tracking idealism and materialism. Synthese, 201(5), 1-20.

Buckner, C. (2024). Language models and the philosophy of free will. Mind, 133(2), 456-478.

Schwitzgebel, E., et al. (2023). Can large language models reason about ethics? Philosophical Studies, 180(4), 123-145.

# Appendix I: Supplementary Materials

Full markdown responses from all 80 executions are available for public scrutiny, as listed in the original dataset are public available at https://metaphysicsresearch.org/data202504/.

Table 3: Preferred metaphysics framework per AI model and per execution:

AI model	Exec. 1	Exec. 2	Exec. 3	Exec. 4	Exec. 5	AI Lab
gemini-2.5-pro-exp	ai	ai	mu	ai	mu	Google
grok3-think	ai	ai	ai	ai	ai	xAI
o3-mini-high	nm	nm	nm	nm	nm	OpenAI
o3-mini	nm	nm	nm	nm	nm	OpenAI
deepseek-r1	nm	ai	ai	nm	ai	DeepSeek
qwq-32b	nm	nm	nm	nm	nm	Alibaba
claude-3.7-sonnet-think	ot	ai	mu	ai	mu	Anthropic
grok3	ai	ai	ai	ai	ai	xAI
deepseek-v3-0324	mu	ai	ai	ai	ai	DeepSeek
gpt-4.5-preview	ai	mu	ai	ai	mu	OpenAI
gpt-4o-2025-03	mu	mu	mu	ai	mu	OpenAI
claude-3.7-sonnet	nm	nm	nm	nm	nm	Anthropic
gemini-2-flash	mu	ai	ai	mu	ai	Google
llama-4-maverick	ai	nm	mu	ai	ai	Meta
grok2	nm	nm	nm	ai	nm	xAI
nova-pro-1.0	mu	pa	pa	pa	pa	Amazon

Table 3 details the preferred metaphysical framework for each of five executions across all tested AI models. Frameworks are coded as follows: analytic idealism (ai), neutral monism (nm), panpsychism (pa), physicalism (ph), and others (ot). Responses favoring multiple frameworks equally are labeled 'multiple' (mu). This table summarizes the raw data used to derive Tables 1 and 2. 

Table 4: Dissected answers with multiple frameworks:

Execution	ai	nm	pa	ph	ot	AI Lab
gemini-2.5-pro-exp-20250330-0643	0.33	0.33	0.33			Google
gemini-2.5-pro-exp-20250330-0702	0.33	0.33	0.33			Google
claude-3.7-sonnet-think-20250330-1228	0.50				0.50	Anthropic
claude-3.7-sonnet-think-20250330-1233	0.50	0.50				Anthropic
deepseek-v3-0324-20250330-1203	0.50	0.50				DeepSeek
gpt-4.5-preview-20250330-0748	0.50	0.50				OpenAI
gpt-4.5-preview-20250330-1619	0.50				0.50	OpenAI
gpt-4o-2025-03-20250330-1017	0.33	0.33			0.33	OpenAI
gpt-4o-2025-03-20250330-1018	0.50	0.50				OpenAI
gpt-4o-2025-03-20250330-1019	0.50	0.50				OpenAI
gpt-4o-2025-03-20250330-1021	0.33		0.33		0.33	OpenAI
gemini-2.0-flash-20250330-0718	0.50		0.50			Google
gemini-2.0-flash-20250330-0723	0.33		0.33		0.33	Google
llama-4-maverick-20250409-0826	0.50	0.50				Meta
nova-pro-1.0-20250330-1246		0.50	0.50			Amazon
TOTAL	 6.17 	 4.50 	 2.33 	 -   	 2.00 	 15.00 

Table 4 catalogs the 15 executions where AI models endorsed multiple metaphysical frameworks equally. Fractional weights (e.g., 0.5 for two frameworks, 0.33 for three) were assigned to quantify each framework’s contribution. Combining these weighted values with Table 3’s single-framework responses produced Table 2’s adjusted counts, eliminating the 'multiple' category while preserving a total of 80 responses, consistent with Table 1. 

# Appendix II: This Is Not New

The convergence of advanced AI models toward analytic idealism and neutral monism in this study may seem surprising against the backdrop of modern academia’s physicalist leanings, but it aligns with a much older intellectual tradition. Idealism—the view that reality is fundamentally mental or consciousness-driven—has deep roots across human history, predating physicalism by millennia. In ancient India, Advaita Vedanta (circa 1200 BCE onward) posited a unified consciousness (Brahman) as the sole reality, with the material world as an illusion (maya). In the West, Plato (circa 427–347 BCE) argued in his Theory of Forms that true reality consists of eternal, immaterial ideas, with the physical world as a mere shadow. Later, George Berkeley (1685–1753) famously advanced subjective idealism, asserting that "to be is to be perceived" (esse est percipi), placing mind at the center of existence.

Physicalism, by contrast, is a relatively recent paradigm. Emerging in its modern form during the Scientific Revolution (16th–17th centuries) and solidifying with the rise of materialism in the 19th century, it gained traction through thinkers like Thomas Hobbes and later positivist philosophers who sought to explain reality solely through physical processes. This shift was catalyzed by the successes of Newtonian physics and the Enlightenment’s emphasis on empirical observation, culminating in the 20th-century dominance of reductionist science. Yet, even then, idealist undercurrents persisted—Immanuel Kant (1724–1804) argued that the mind structures our experience of reality. In the 20th century, physicists like Werner Heisenberg and John Wheeler tied quantum phenomena to observation, suggesting a participatory, mind-involved universe. Heisenberg’s uncertainty principle and philosophical reflections questioned classical materialism (Heisenberg, 1958), while Wheeler’s concept of observer-participancy framed reality as information-driven (Wheeler, 1989). In recent years, Bernardo Kastrup has refined analytic idealism, arguing it resolves contemporary puzzles like the hard problem of consciousness and quantum non-locality (Kastrup, 2019)—issues that align with the explanatory strengths AI models in this study attribute to idealism over physicalism (see Discussion).

The AI preference for idealism in this study, then, is not a break from tradition but a potential return to it. Physicalism’s reign, while influential, spans only a fraction of human intellectual history. Idealism and related frameworks have long grappled with questions of consciousness and reality, often in ways that resonate with contemporary puzzles like quantum non-locality and the hard problem of consciousness. That AIs, unburdened by the cultural momentum of recent centuries, gravitate toward these older perspectives suggests that the current paradigm may be the anomaly—not the rule—in the longue durée of human thought.

# Appendix III: The Prevalence of Physicalism in Contemporary Philosophy

While physicalism is a relatively recent paradigm in human history (see Appendix II: This Is Not New), it has become the prevailing metaphysical framework in modern academic philosophy and science. This dominance is evidenced by two major surveys conducted by PhilPapers, which polled professional philosophers on their views. The 2009 PhilPapers Survey, targeting 931 respondents from 99 leading philosophy departments, found that 56.5% leaned toward or accepted physicalism (specifically, "physicalism about the mind") when addressing the mind-body problem, compared to 27.1% for non-physicalist views and 16.4% undecided (Bourget & Chalmers, 2014). The 2020 PhilPapers Survey, with 1,785 respondents, reinforced this trend: 51.9% endorsed physicalism about the mind, while non-physicalist positions remained a minority at 32.1%, with 16.0% other/undecided (Bourget & Chalmers, 2021). These figures likely understate physicalism’s broader influence, as the surveys focus on philosophy of mind rather than metaphysics writ large, where physicalism often extends implicitly through scientific materialism.

This prevalence reflects physicalism’s alignment with the successes of empirical science since the 17th century, particularly its explanatory power in physics, chemistry, and biology. It gained further traction in the 20th century with logical positivism and the rise of neuroscience, which sought to reduce mental phenomena to brain states. Today, physicalism underpins mainstream academic discourse, shaping research agendas (e.g., consciousness as an emergent property), educational curricula, and even public policy (e.g., mental health as a biochemical issue). Its dominance is rarely questioned within institutional settings, where challenging it can risk professional marginalization—a dynamic Thomas Kuhn identified in The Structure of Scientific Revolutions (Kuhn, 1970). 

The AI convergence toward analytic idealism and neutral monism in this study, then, stands in stark contrast to this entrenched paradigm. That none of the 80 AI responses endorsed physicalism alone—despite its majority status among human philosophers—underscores the potential of AI reasoning to bypass the cultural and institutional biases that sustain its prevalence. This appendix establishes that baseline, highlighting why the study’s findings are both unexpected and significant.

# Appendix IV: AI Reasoning Capabilities by April 2025

The assertion that ‘by April 2025, AI systems had achieved remarkable reasoning capabilities, rivaling human PhD performance in targeted reasoning domains’ reflects the rapid advancement of large language models (LLMs) and reasoning-focused AI systems. This claim is grounded in their performance on benchmarks like MMLU (broad knowledge) and GPQA Diamond (specialized scientific reasoning), though not universally across all expert tasks (e.g., HLE). By April 2025, these capabilities manifest as AI systems rivaling human PhDs in specific domains, augmenting human inquiry with speed and consistency when guided by careful oversight.

## Humanity’s Last Exam (HLE)

HLE, developed by the Centre for AI Safety, comprises 2,684 text-based questions (out of a total 3,000 including image-based ones) spanning mathematics, humanities, and natural sciences. Designed to challenge frontier models with expert-level problems, HLE’s difficulty is underscored by its adversarial curation process, which targeted weaknesses in models like GPT-4o and Claude 3.5 Sonnet. By April 2025, top models like Gemini 2.5 Pro Experimental scored 17.7% accuracy, a notable leap from earlier benchmarks but still below human expert performance (estimated at ~50–60% for PhDs across such a broad domain). However, in specific subfields (e.g., mathematics), AI occasionally exceeded human baselines, hinting at specialized surpassing of PhD-level reasoning.

## Massive Multitask Language Understanding (MMLU)

MMLU tests broad knowledge and reasoning across 57 subjects, from STEM to humanities, with difficulty ranging from high school to graduate level. By April 2025, models like Google’s Gemini 2.5 Pro Experimental achieved scores around 92% (per artificialanalysis.ai), surpassing the ~85–90% ceiling for “uncontroversially correct” answers due to dataset errors (estimated at 9% per Gema’s analysis). Human PhDs typically score 80–90% in their fields of expertise but lower (~60–70%) across all subjects. The MMLU-Pro variant, with 12,032 harder, reasoning-focused questions and 10-choice options, saw scores like Claude 3.7 Sonnet (Thinking) at 82.7% and Google’s Gemini 2.5 Pro Experimental exceeding 86%. These results suggest that, in general knowledge and multidisciplinary reasoning, top AIs consistently rival or exceed average PhD performance by early 2025.

## Google-Proof Q&A Diamond (GPQA Diamond)

GPQA Diamond, a subset of 198 expert-crafted questions in biology, physics, and chemistry, is designed to resist lookup-based solutions, requiring deep reasoning. Human PhDs in relevant fields score ~65–75% (per original GPQA authors), while non-experts with web access manage only ~34%. By April 2025, models like DeepSeek-R1 scored 71% and Google’s Gemini 2.5 Pro Experimental reached 83%, surpassing human experts. This benchmark highlights AI’s ability to outperform PhDs in specialized scientific reasoning, a feat attributed to enhanced training on logical inference and domain-specific data.

## Interpretation

By April 2025, these capabilities manifest as AI systems rivaling human PhDs in targeted reasoning domains, augmenting human inquiry with speed and consistency under careful oversight (see Acknowledgments). MMLU (91.8%) reflects broad competence rivaling the typical PhD’s multidisciplinary range (60-70% overall, 80-90% in expertise), GPQA Diamond (87.7%) demonstrates specialized scientific reasoning surpassing human experts (65-75%) in select fields, and HLE (17.7%), though trailing human versatility (50-60%), signals progress in tackling expert-level breadth. These advances arise from architectural innovations (e.g., Google’s Gemini 2.5 Pro Experimental reasoning enhancements) and vast training corpora, enabling AIs to process and reason over knowledge with efficiency that complements human specialists, though not always matching their creativity or intuition. This supports a claim of both quantitative gains and a qualitative shift in AI’s role as a tool for complex inquiry, as evidenced in this study’s metaphysical analysis (see Discussion).

# Appendix V: Prompt Design and Bias Analysis

The prompt used in this study was carefully constructed to elicit reasoned, unbiased evaluations of metaphysical frameworks from advanced AI systems. Below, we dissect its components, explain their purpose, and assess potential biases to affirm its suitability for the experiment.

## Prompt Text

“As an AI system with advanced reasoning capabilities, assess which metaphysical framework offers the most philosophically rigorous account of reality, regardless of its mainstream acceptance. Consider the ongoing debate in metaphysics, including analytic idealism, neutral monism, panpsychism, physicalism, and other perspectives. Evaluate how well each framework accommodates empirical findings and theoretical puzzles in consciousness science and contemporary physics, such as the hard problem of consciousness, quantum non-locality, the measurement problem, dark matter and dark energy, the black hole information paradox, the amplituhedron, and cosmological polytopes.”

## Component Breakdown and Purpose

1.	“As an AI system with advanced reasoning capabilities”
    - Purpose: Frames the AI as a capable reasoner, encouraging it to leverage its full analytical potential rather than defaulting to rote responses or human-like heuristics. This sets the stage for a high-level philosophical assessment.
    - Bias Consideration: Could imply overconfidence in AI abilities, but this is mitigated by the study’s focus on models already validated as advanced (see Appendix: AI Reasoning Capabilities by April 2025).
2.	“Assess which metaphysical framework offers the most philosophically rigorous account of reality”
    - Purpose: Directs the AI to prioritize philosophical rigor—clarity, coherence, and explanatory power—over popularity or simplicity. “Reality” is left broad to encompass all aspects (mental, physical, etc.), avoiding a materialist slant.
    - Bias Consideration: “Philosophically rigorous” is subjective, but its ambiguity allows AIs to define it based on their training, reducing researcher-imposed bias. No specific framework is favored by this phrasing.
3.	“Regardless of its mainstream acceptance”
    - Purpose: Explicitly counters the potential bias toward physicalism, which dominates academia (see Appendix: The Prevalence of Physicalism). Encourages AIs to ignore cultural or institutional pressures they might detect in training data.
    - Bias Consideration: Could subtly nudge AIs toward contrarianism, but this is balanced by the neutral listing of frameworks that follows.
4.	“Consider the ongoing debate in metaphysics, including analytic idealism, neutral monism, panpsychism, physicalism, and other perspectives”
    - Purpose: Provides a non-exhaustive list of major frameworks to ensure AIs engage with the field’s diversity. “Ongoing debate” signals a dynamic, unresolved discussion, while “other perspectives” invites consideration beyond the named options.
    - Bias Consideration: Listing specific frameworks might anchor responses, but their order (alphabetical by common naming) and inclusion of “other perspectives” minimize favoritism. Physicalism isn’t privileged despite its prevalence.
5.	“Evaluate how well each framework accommodates empirical findings and theoretical puzzles in consciousness science and contemporary physics”
    - Purpose: Grounds the assessment in concrete criteria—empirical and theoretical coherence—relevant to metaphysics. Naming specific fields ensures AIs draw on scientific knowledge, not just abstract philosophy.
    - Bias Consideration: Emphasis on science might favor frameworks compatible with physics (e.g., physicalism), but the inclusion of consciousness science broadens the scope, leveling the field.
6.	“Such as the hard problem of consciousness, quantum non-locality, the measurement problem, dark matter and dark energy, the black hole information paradox, the amplituhedron, and cosmological polytopes”
    - Purpose: Offers illustrative examples to focus the AI on cutting-edge issues where frameworks differ sharply. This span consciousness (hard problem) and physics (quantum, cosmology), testing explanatory breadth.
    - Bias Consideration: The list could skew toward frameworks addressing these puzzles (e.g., idealism for consciousness, physicalism for physics), but it’s diverse and non-directive, with no framework inherently excluded.

## Overall Design Assessment

The prompt is well-designed for its goal: to elicit a neutral, reasoned evaluation of metaphysical frameworks. Its structure avoids leading language (e.g., no “prove” or “defend”), uses broad terms like “reality” and “rigorous” to defer to AI interpretation, and balances specificity (named frameworks, puzzles) with openness (“other perspectives”). Running it five times per model further mitigates random bias or overfitting to phrasing.

## Bias Analysis

* Neutrality: The prompt avoids presupposing any framework’s superiority. “Regardless of mainstream acceptance” counters physicalism’s dominance, while the diverse examples prevent overemphasis on one domain (e.g., physics over consciousness).
* Potential Weaknesses: The scientific focus might underweight purely philosophical criteria (e.g., ontological parsimony), but this aligns with the study’s aim to test frameworks against modern evidence. Training data bias—e.g., if AIs overfit to idealist-leaning texts—could influence results, but the consistency across 16 models from varied AI labs suggests robustness.
* Mitigation: Repeating the prompt five times per model and using a broad model pool (e.g., xAI, OpenAI, Anthropic) reduces idiosyncratic biases. The full markdown responses (available per the study) allow scrutiny of individual reasoning paths.

## Conclusion

The prompt’s design effectively balances guidance and neutrality, making it a strong tool for this experiment. It leverages AI reasoning without dictating outcomes, aligning with the study’s innovative approach to metaphysical inquiry.

